# -*- coding: utf-8 -*-
"""sravani.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r6qJ2Hl-YE1HHUDO2txnGQUEJaDMRh8-
"""

import os
import numpy as np
import cv2
import tensorflow as tf
import keras
import matplotlib.pyplot as plt
from keras import backend as k
from skimage import io
from keras_preprocessing.image import ImageDataGenerator

from google.colab import drive
drive.mount('/content/drive')

# pip install keras_preprocessing

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import cv2
from skimage import io
import tensorflow as tf
from tensorflow.python.keras import Sequential
from tensorflow.keras import layers, optimizers
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.initializers import glorot_uniform
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from IPython.display import display
from tensorflow.keras import backend as K
import os
# %matplotlib inline

brain_df = pd.read_csv('/content/data_mask.csv')

brain_df.head()

brain_df.isna().sum()

brain_df.shape

sns.countplot(brain_df['mask'])
plt.show()

brain_df.image_path[0]

brain_df.mask_path[0]

cv2.imread(r'/content/drive/MyDrive/kaggle_3m/TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_5_mask.tif')

# case when we have brain tumor
folder_path = '/content/drive/MyDrive/kaggle_3m/'
fig, axes = plt.subplots(1, 2, figsize=(7,7))
axes[0].imshow(cv2.imread(folder_path+ brain_df.mask_path[445]))
axes[1].imshow(cv2.imread(folder_path+brain_df.image_path[445]))
plt.show()

count = 0
fig, axes = plt.subplots(5, 3, figsize = (20, 30))
for i in range(len(brain_df)):
  if brain_df['mask'][i] == 1 and count < 5:

    img = io.imread(folder_path+brain_df.image_path[i])
    axes[count][0].set_title('Brain MRI')
    axes[count][0].imshow(img)

    mask = io.imread(folder_path+brain_df.mask_path[i])
    axes[count][1].set_title('Mask')
    axes[count][1].imshow(mask, cmap='gray')

    img[mask == 255] = (255, 0, 0) # make brain tumor red on original brain MRI
    axes[count][2].set_title('MRI with Mask')
    axes[count][2].imshow(img)
    count+=1
fig.tight_layout()

""" ## Model to detect if there's a brain tumor

"""

brain_df_train = brain_df.drop(columns = ['patient_id'])
brain_df_train.shape

brain_df.info()
# need to convert 'mask' column to str type,
# otherwise Image data generator will give you an error, if you want to use 'categorical mode'

brain_df_train['mask'] = brain_df_train['mask'].apply(lambda x: str(x))

from keras_preprocessing.image import ImageDataGenerator
image_data_gen = ImageDataGenerator(rescale=1./255., validation_split = 0.15)
test_data_gen = ImageDataGenerator(rescale=1./255.)

from sklearn.model_selection import train_test_split
train, test = train_test_split(brain_df_train, test_size = 0.15)

batch = 16

train_gen = image_data_gen.flow_from_dataframe(dataframe=train,
                                               directory='/content/drive/MyDrive/kaggle_3m',
                                               x_col='image_path', y_col='mask',
                                               subset='training',
                                               batch_size=batch,
                                               shuffle=True,
                                               class_mode='categorical',
                                               target_size=(256, 256))
val_gen = image_data_gen.flow_from_dataframe(dataframe=train,
                                               directory='/content/drive/MyDrive/kaggle_3m',
                                               x_col='image_path', y_col='mask',
                                               subset='validation',
                                               batch_size=batch,
                                               shuffle=True,
                                               class_mode='categorical',
                                               target_size=(256, 256))
test_gen = test_data_gen.flow_from_dataframe(dataframe=test,
                                               directory='/content/drive/MyDrive/kaggle_3m',
                                               x_col='image_path', y_col='mask',
                                               batch_size=batch,
                                               shuffle=False,
                                               class_mode='categorical',
                                               target_size=(256, 256))

test['mask'].value_counts()

resnet = ResNet50(include_top=False, input_tensor=Input((256, 256, 3)))
#resnet.summary()

def freeze_or_tune(tune=True):
  if tune:
    resnet.trainable = True
  else:
    resnet.trainable = False

# optional
freeze_or_tune(True)

# for Fine tuning (not the whole resnet will be tuned)
for i in range(len(resnet.layers)):
  if resnet.layers[i].name.startswith('conv5') or resnet.layers[i].name.startswith('conv4') or resnet.layers[i].name.startswith('conv3'):
    resnet.layers[i].trainable = True
  else:
    resnet.layers[i].trainable = False

# look at this table and make sure that necessary layers trainable or not
layers = [(layer, layer.name, layer.trainable) for layer in resnet.layers]
df = pd.DataFrame(layers, columns=['layer', 'name', 'is_trainable'])
df[df['is_trainable']==True]

# build model
X = resnet.output
X = AveragePooling2D((4, 4))(X)
X = Flatten(name='flatten')(X)
X = Dense(256, activation='relu')(X)
X = Dropout(0.3)(X)
X = Dense(256, activation='relu')(X)
X = Dropout(0.3)(X)
X = Dense(256, activation='relu')(X)
X = Dropout(0.3)(X)
output = Dense(2, activation='softmax')(X)
model = Model(inputs=resnet.input, outputs=output)

model.summary()

model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0001), metrics= ['accuracy'])

length_of_train_gen = train_gen.n
print("Length of train_gen:", length_of_train_gen)

train_gen

earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)
path_checkpoint = '/content/drive/MyDrive/models/model_checkpoint_{epoch:02d}.h5'
checkpoint = ModelCheckpoint(filepath=path_checkpoint, verbose=1, save_best_only=True,save_freq=5)

history = model.fit(train_gen, steps_per_epoch=train_gen.n // batch,
                    epochs=20, validation_data=val_gen,
                    validation_steps=val_gen.n // batch,
                    callbacks=[checkpoint, earlystopping])

model.save("/content/drive/MyDrive/classifier-resnet-weights_fine_tuning_16b_345.hdf5")

model_json = model.to_json()
with open('model_fine_tuning_16b_345_3.json', 'w') as json_file:
  json_file.write(model_json)



img = io.imread("/content/drive/MyDrive/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_1.tif")
plt.imshow(img)

img = img * 1./255.
img = cv2.resize(img, (256, 256))
img = np.array(img, dtype=np.float64)
img = np.reshape(img, (1, 256, 256, 3))

with open('/content/model_fine_tuning_16b_345_3.json', 'r') as json_file:
    json_saved_model = json_file.read()
model1 = tf.keras.models.model_from_json(json_saved_model)
model1.load_weights('/content/drive/MyDrive/classifier-resnet-weights_fine_tuning_16b_345.hdf5')
model1.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0001), metrics=['accuracy'])

folder_path = '/content/drive/MyDrive/kaggle_3m/'
ans=[]
for i in range(len(brain_df)):
  img = io.imread(folder_path+brain_df.image_path[i])
  img = img * 1./255.
  img = cv2.resize(img, (256, 256))
  img = np.array(img, dtype=np.float64)
  img = np.reshape(img, (1, 256, 256, 3))
  # img = brain_df['image_path'][i]

  is_defect = model1.predict(img)

  predicted_class = np.argmax(is_defect)
  ans.append(predicted_class)
  # if predicted_class==1:
    # print(i)
  print("Predicted class:", predicted_class)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score

test.shape

with open('model_fine_tuning_16b_345.json', 'r') as json_file:
  json_saved_model = json_file.read()
model1 = tf.keras.models.model_from_json(json_saved_model)
model1.load_weights('classifier-resnet-weights_fine_tuning_16b_345.hdf5')
model1.compile(loss ='categorical_crossentropy', optimizer=optimizers.Adam(0.0001), metrics= ['accuracy'])

preds1 = model1.predict(test_gen, steps=test_gen.n // batch, verbose=1)
preds1 = np.argmax(preds1, axis=1)
true = np.asarray(test['mask'][:len(preds1)], dtype='int32')
accuracy1 = accuracy_score(true, preds1)
accuracy1 # accuracy - 0.979

with open('model_fine_tuning_16b_345_2.json', 'r') as json_file:
  json_saved_model = json_file.read()
model2 = tf.keras.models.model_from_json(json_saved_model)
model2.load_weights('classifier-resnet-weights_fine_tuning_16b_345_2.hdf5')
model2.compile(loss ='categorical_crossentropy', optimizer=optimizers.Adam(0.0001), metrics= ['accuracy'])

preds2 = model2.predict(test_gen, steps=test_gen.n // batch, verbose=1)
preds2 = np.argmax(preds2, axis=1)
true = np.asarray(test['mask'][:len(preds2)], dtype='int32')

accuracy2 = accuracy_score(true, preds2)
accuracy2 # accuracy - 0.984





